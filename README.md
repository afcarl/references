# Deep Learning reading lists
# 2011-present

### Eugenio Culurciello



# Basic Machine Learning:
https://www.coursera.org/course/ml


# CNN, convnets from online courses:
https://www.cs.ox.ac.uk/people/nando.defreitas/machinelearning/
http://cs231n.stanford.edu/syllabus.html



# RNN - recurrent neural nets:

## nice explanation
https://www.cs.ox.ac.uk/people/nando.defreitas/machinelearning/
http://karpathy.github.io/2015/05/21/rnn-effectiveness/

## RNN code is here:
https://github.com/karpathy/char-rnn
https://github.com/wojzaremba/lstm


##RNN Recurrent neural networks useful links

Graphs in Torch: You need this before attempting to start digesting the LSTM code.
Exercise: https://www.cs.ox.ac.uk/people/nando.defreitas/machinelearning/practicals/practical5.pdf
Nando de Freitas lecture

Videos:
https://youtu.be/56TYLaQN4N8 (LSTM basics)
https://youtu.be/-yX1SYeDHbg (Alex Graves’s hand-writer algorithm)
Sides: https://www.cs.ox.ac.uk/people/nando.defreitas/machinelearning/lecture11.pdf
Exercise: https://www.cs.ox.ac.uk/people/nando.defreitas/machinelearning/practicals/practical6.pdf

Soumith article
http://devblogs.nvidia.com/parallelforall/understanding-natural-language-deep-neural-networks-using-torch/

Ilya Sutskever NIPS paper
Sequence to Sequence Learning with Neural Networks
http://arxiv.org/abs/1409.3215

Alex Graves (43 pages) paper
Generating Sequences With Recurrent Neural Networks
Prediction network – Long Short-term Memory Cell
Text Prediction
Penn Treebank Experiments
Wikipedia Experiments
Handwriting Prediction
Handwriting Synthesis
http://arxiv.org/abs/1308.0850

Alex Graves LSTM paper
Speech Recognition with Deep Recurrent Neural Networks
http://arxiv.org/abs/1303.5778

Wojciech Zaremba regularisation paper
Recurrent Neural Network Regularization
http://arxiv.org/abs/1409.2329

Hochreiter & Schmidhuber (the article)
http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf

Schmidhuber website
Plenty of applications and references
http://people.idsia.ch/~juergen/rnn.html

Schmidhuber LSTM tutorial
Video: https://www.youtube.com/watch?v=JSNZA8jVcm4
Slides: http://people.idsia.ch/~juergen/deep2014white.pdf

Andrej Karpathy blog post
Link: http://karpathy.github.io/2015/05/21/rnn-effectiveness/

Understanding LSTM modules
http://colah.github.io/posts/2015-08-Understanding-LSTMs/

And its uses:
http://colah.github.io/posts/2014-07-NLP-RNNs-Representations/

LSTM code torch explained by Adam:
https://apaszke.github.io/lstm-explained.html



## how to design neural nets:

VGG https://arxiv.org/pdf/1409.1556.pdf

PreLU http://arxiv.org/pdf/1603.05201v1.pdf

Inception v4 http://arxiv.org/abs/1602.07261

Inception v3 http://arxiv.org/abs/1409.4842

Inception v2 http://arxiv.org/abs/1512.00567

ResNet http://arxiv.org/abs/1512.03385

NiN http://arxiv.org/abs/1312.4400

systematic evaluation of modules:https://arxiv.org/abs/1606.02228

# unsupervised

Soumith DCGAN
http://arxiv.org/abs/1511.06434

Solving Puzzles
http://arxiv.org/abs/1603.09246

co-occurence patches
https://arxiv.org/abs/1511.06811
http://graphics.cs.cmu.edu/projects/deepContext/

surrogate classes
http://arxiv.org/abs/1406.6909

video LSTM
http://arxiv.org/abs/1502.04681

learn to generate images from textual descriptions.
https://arxiv.org/abs/1605.05396

predicting next frames from video, MIT Torralba
http://arxiv.org/abs/1504.08023

# Reinforcement Learning

http://karpathy.github.io/2016/05/31/rl/

# other lists:

https://github.com/terryum/awesome-deep-learning-papers




# transfer learning:

this paper on using CNN transfer learning ability to reach state-of-art in a lot of other dataset (transferred from ImageNet training):
http://arxiv.org/abs/1403.6382

This great paper also shows transfer from ImageNet to PASCAL VOC:
http://www.di.ens.fr/~josef/publications/oquab14.pdf

And this paper from Bengio group also has a great analysis:
https://papers.nips.cc/paper/5347-how-transferable-are-features-in-deep-neural-networks.pdf
https://arxiv.org/abs/1411.1792

This work on image segmentation also use transfer learning of VGG CNN networks:
http://arxiv.org/abs/1511.00561 

and more details here in this Stanford course material:
http://cs231n.github.io/transfer-learning/
http://cs231n.stanford.edu/reports2016/001_Report.pdf
http://cs231n.stanford.edu/reports2016/313_Report.pdf

transfer learning vs fully trained for vehicle model 
http://cs231n.stanford.edu/reports/lediurfinal.pdf


# Artistic style
- https://arxiv.org/abs/1508.06576
